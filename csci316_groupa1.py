# -*- coding: utf-8 -*-
"""CSCI316_GroupA1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uEVrpGy53hir72eDvC5CbwXcxaakd1Zp

## CSCI316 Group Assignment 1

### **Importing Libraries and Dataset**
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random

# import the train_test_split from model_selection
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier, plot_tree # Import Decision Tree Classifier
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation
from sklearn import tree

#Transformer imports
from sklearn.base import BaseEstimator, TransformerMixin

#Logistic Regression imports
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score

#KNN
from sklearn.neighbors import KNeighborsClassifier
from matplotlib.colors import ListedColormap

#Random Forest
from sklearn.ensemble import RandomForestClassifier

data = pd.read_csv('/content/drive/MyDrive/data.csv', low_memory=False)
#low_memory=false : there are columns with different datatypes. this ignores the error
print("Number of samples of data :%d" % len(data))
print(data)

print("Columns:")
for col in data.columns:
    print(col)

"""### **(a) Discover and Visualise Data**"""

data.info()
data.describe()

"""**Correlation Heatmap**"""

# Visualize the correlation of all columns
plt.figure(figsize=(1,25))
heatmap = sns.heatmap(data.corr()[['default_ind']].sort_values
                     (by='default_ind', ascending=False), vmin=-1,
                      vmax=1, annot=True, cmap='YlGnBu')

heatmap.set_title('Features Correlating with default_ind',
                  fontdict={'fontsize':20}, pad=14);

"""**Selection of top 20 correlation columns**"""

# 20 selected columns (highest correlation to default_ind)
df20 = pd.DataFrame(data,columns=['pub_rec','mths_since_last_major_derog','collections_12_mths_ex_med',
                               'delinq_2yrs','funded_amnt_inv','funded_amnt','loan_amnt',
                               'acc_now_delinq','tot_coll_amt','mths_since_last_delinq','dti',
                                'installment','revol_util','total_rec_int','mths_since_last_record',
                                'inq_last_6mths','total_rec_late_fee','int_rate','collection_recovery_fee',
                                'recoveries','default_ind'])

# return correlation matrix of df20
corr = df20.corr()
corr = corr['default_ind'].sort_values()
corr

"""**Visualization for correlation of 20 selected columns (Confusion Matrix)**"""

# visualize the correlation of all columns in df20
plt.figure(figsize=(25,15))

# using heapmap to plot
sns.heatmap(df20.corr(), annot=True)

# show the plot
plt.show()

"""**Visualization for "recoveries" and "collection_recovery_fee" to "default_ind" (Scatterplot)**"""

sns.catplot(data=df20, x="default_ind", y="recoveries")

sns.catplot(data=df20, x="default_ind", y="collection_recovery_fee")

"""**Visualization for count of "default_ind" (Bar Graph)**"""

data.groupby('default_ind').size()

# visualize the count of each 'default_ind' in data
plt.title('Count of each default_ind')
sns.set_style('whitegrid')
sns.countplot(x=data['default_ind'],palette='Paired')
plt.show()

"""**Visualization for percentage of each "default_ind" (Pie Chart)**"""

plt.figure(figsize=(5, 5))
data['default_ind'].value_counts().plot(kind='pie', autopct='%1.1f%%')
plt.ylabel('')
plt.title('Percentage of each default_ind')
plt.show()

"""### **(b) Prepare the data for machine learning**

Filled rows with missing values with median value and check new correlation with default_ind
"""

# filling empty cells with median value
median_per_column = df20.median()

new_data = df20.fillna(median_per_column)
new_data.head()

#  returns the correlation matrix of the df to check that it hasn't deviated too much from original value
corr = new_data.corr()
corr = corr['default_ind'].sort_values()
corr

"""**User-Defined Transformer**"""

# feature engineering transformer
class AddNewFeatureTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, add_new_feature=True):
        self.add_new_feature = add_new_feature

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        new_data = X.copy()  # Create a copy of the input DataFrame

        if self.add_new_feature:
            # create a new feature called "recovery_performed," which takes the value 0 if no recoveries were performed and 1 if recoveries were performed.
            # this new feature will be based on the "recoveries" and "collection_recovery_fee" columns, where any value greater than 0 will indicate that a recovery has been performed.
            new_data['recovery_performed'] = ((new_data['recoveries'] > 0) | (new_data['collection_recovery_fee'] > 0)).astype(int)

        return new_data

"""### **(c) Select and train models**"""

# Split the data into training and testing sets
# pre-transformed data
before_transform = AddNewFeatureTransformer(False)
bef_trans_data = before_transform.fit_transform(new_data)

# transformed data
after_transform = AddNewFeatureTransformer(True)
aft_trans_data = after_transform.fit_transform(new_data)

corr = aft_trans_data.corr()
corr = corr['default_ind'].sort_values()
corr

# x and y for pre-transformed df
x = bef_trans_data.drop(columns=['default_ind']).values
y = bef_trans_data['default_ind'].values
x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2,random_state=0)

# x1 and y1 for transformed df
x1 = aft_trans_data.drop(columns=['default_ind']).values
y1 = aft_trans_data['default_ind'].values
x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1,test_size=0.2,random_state=0)


print("X training set count is : %.1f%% of total records" %
    (len(x_train)/len(x)*100))
print("X testing set count is : %.1f%% of total records\n" %
    (len(x_test)/len(x)*100))
print("Y training set count is : %.1f%% of total records" %
    (len(y_train)/len(x)*100))
print("Y testing set count is : %.1f%% of total records" %
    (len(y_test)/len(x)*100))

print("\n\nX1 training set count is : %.1f%% of total records" %
    (len(x_train)/len(x)*100))
print("X1 testing set count is : %.1f%% of total records\n" %
    (len(x_test)/len(x)*100))
print("Y1 training set count is : %.1f%% of total records" %
    (len(y_train)/len(x)*100))
print("Y1 testing set count is : %.1f%% of total records" %
    (len(y_test)/len(x)*100))

"""### Decision Tree Classifier

Using pre-transformed dataframe
"""

# Create Decision Tree classifer object
dtc = DecisionTreeClassifier()

# Train Decision Tree Classifer
dtc = dtc.fit(x_train,y_train)

#Predict the response for test dataset
y_pred = dtc.predict(x_test)

# Model Accuracy
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision: ", metrics.precision_score(y_test, y_pred))
print("Recall: ", metrics.recall_score(y_test, y_pred))

# Detailed metrics using classification_report
print("\nClassification Report:", classification_report(y_test, y_pred))

"""Using transformed dataframe"""

# Create Decision Tree classifer object
dtc = DecisionTreeClassifier()

# Train Decision Tree Classifer
dtc = dtc.fit(x_train1,y_train1)

#Predict the response for test dataset
y_pred1 = dtc.predict(x_test1)

# Model Accuracy
print("Accuracy:",metrics.accuracy_score(y_test1, y_pred1))
print("Precision: ", metrics.precision_score(y_test1, y_pred1))
print("Recall: ", metrics.recall_score(y_test1, y_pred1))

# Detailed metrics using classification_report
print("\nClassification Report:", classification_report(y_test1, y_pred1))

"""Fine-tuning on pre-transformed dataframe"""

param_grid = {
    'criterion': ['gini', 'entropy'], # function to measure quality of split
    'max_features': [None, 'sqrt', 'log2'] # num of features to consider when looking for best split
}

grid_search = GridSearchCV(dtc, param_grid)
grid_search.fit(x_train, y_train)
best_params = grid_search.best_params_

final_dtc = DecisionTreeClassifier(**best_params)
final_dtc.fit(x_train, y_train)
y_pred_f = final_dtc.predict(x_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred_f))
print("Best Parameters:", best_params)

"""Fine-tuning on transformed dataframe"""

param_grid = {
    'criterion': ['gini', 'entropy'], # function to measure quality of split
    'max_features': [None, 'sqrt', 'log2'] # num of features to consider when looking for best split
}

grid_search = GridSearchCV(dtc, param_grid)
grid_search.fit(x_train1, y_train1)
best_params = grid_search.best_params_

final_dtc = DecisionTreeClassifier(**best_params)
final_dtc.fit(x_train1, y_train1)
y_pred_f = final_dtc.predict(x_test1)

print("Accuracy:",metrics.accuracy_score(y_test1, y_pred_f))
print("Best Parameters:", best_params)

"""### Logistic Regression

Using pre-transformed dataframe
"""

logreg = LogisticRegression(solver='liblinear')
logreg.fit(x_train, y_train)
y_pred = logreg.predict(x_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision:",metrics.precision_score(y_test, y_pred))
print("Recall:",metrics.recall_score(y_test, y_pred))

print("\nClassification Report:\n",metrics.classification_report(y_test, y_pred))

"""Using transformed dataframe"""

logreg = LogisticRegression(solver='liblinear')
logreg.fit(x_train1, y_train1)
y_pred1 = logreg.predict(x_test1)

print("Accuracy:",metrics.accuracy_score(y_test1, y_pred1))
print("Precision:",metrics.precision_score(y_test1, y_pred1))
print("Recall:",metrics.recall_score(y_test1, y_pred1))

print("\nClassification Report:\n",metrics.classification_report(y_test1, y_pred1))

"""Fine-tuning on pre-transformed dataframe"""

param_grid = {
    'C': [0.1, 1.0, 10.0], # inverse regularization strength
    'penalty': ['l1', 'l2'], # regularization type
}

grid_search = GridSearchCV(logreg, param_grid)
grid_search.fit(x_train, y_train)
best_params = grid_search.best_params_

final_logreg = LogisticRegression(solver='liblinear', **best_params)
final_logreg.fit(x_train, y_train)
y_pred_f = final_logreg.predict(x_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred_f))
print("Best Parameters:", best_params)

"""Fine-tuning on transformed dataframe"""

param_grid = {
    'C': [0.1, 1.0, 10.0], # inverse regularization strength
    'penalty': ['l1', 'l2'], # regularization type
}

grid_search = GridSearchCV(logreg, param_grid)
grid_search.fit(x_train1, y_train1)
best_params = grid_search.best_params_

final_logreg = LogisticRegression(solver='liblinear', **best_params)
final_logreg.fit(x_train1, y_train1)
y_pred_f = final_logreg.predict(x_test1)

print("Accuracy:",metrics.accuracy_score(y_test1, y_pred_f))
print("Best Parameters:", best_params)

"""### Random Forest Classifier

Using pre-transformed dataframe
"""

rfc = RandomForestClassifier(max_depth=3)

# Train Random Forest Classifier
rfc.fit(x_train, y_train)

# Predict the response for the test dataset
y_pred = rfc.predict(x_test)

# Model Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))

# Detailed metrics using classification_report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

"""Using transformed dataframe"""

rfc = RandomForestClassifier(max_depth=3)

# Train Random Forest Classifier
rfc.fit(x_train1, y_train1)

# Predict the response for the test dataset
y_pred1 = rfc.predict(x_test1)

# Model Evaluation
print("Accuracy:", accuracy_score(y_test1, y_pred1))
print("Precision:", precision_score(y_test1, y_pred1))
print("Recall:", recall_score(y_test1, y_pred1))

# Detailed metrics using classification_report
print("\nClassification Report:")
print(classification_report(y_test1, y_pred1))

"""Fine-tuning on pre-transformed dataframe"""

param_grid = {
    'criterion': ['gini', 'entropy'],  # split criterion for decision trees
}

grid_search = GridSearchCV(rfc, param_grid)
grid_search.fit(x_train, y_train)
best_params = grid_search.best_params_

final_rfc = RandomForestClassifier(max_depth=3, **best_params)
final_rfc.fit(x_train, y_train)
y_pred_f = final_rfc.predict(x_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred_f))
print("Best Parameters:", best_params)

"""Fine-tuning on transformed dataframe"""

param_grid = {
    'criterion': ['gini', 'entropy'],  # split criterion for decision trees
}

grid_search = GridSearchCV(rfc, param_grid)
grid_search.fit(x_train1, y_train1)
best_params = grid_search.best_params_

final_rfc = RandomForestClassifier(max_depth=3, **best_params)
final_rfc.fit(x_train1, y_train1)
y_pred_f = final_rfc.predict(x_test1)

print("Accuracy:",metrics.accuracy_score(y_test1, y_pred_f))
print("Best Parameters:", best_params)

"""### KNN (K-Nearest Neighbour)

Using pre-transformed dataframe
"""

# Create KNN classifier object with k=5
knn = KNeighborsClassifier(n_neighbors=5)

# Train KNN Classifier
knn.fit(x_train, y_train)

# Predict the response for the test dataset
y_pred = knn.predict(x_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))

"""Using transformed dataframe"""

# Create KNN classifier object with k=5
knn = KNeighborsClassifier(n_neighbors=5)

# Train KNN Classifier
knn.fit(x_train1, y_train1)

# Predict the response for the test dataset
y_pred1 = knn.predict(x_test1)

print("Accuracy:", accuracy_score(y_test1, y_pred1))
print("Precision:", precision_score(y_test1, y_pred1))
print("Recall:", recall_score(y_test1, y_pred1))

"""Fine-tuning on pre-transformed dataframe"""

param_grid = {
    'weights': ['uniform', 'distance'],  # weighting scheme for neighbors
    'p': [1, 2],  # power parameter for the Minkowski distance metric (1: Manhattan, 2: Euclidean)
}

grid_search = GridSearchCV(knn, param_grid)
grid_search.fit(x_train, y_train)
best_params = grid_search.best_params_

final_knn = KNeighborsClassifier(n_neighbors=5, **best_params)
final_knn.fit(x_train, y_train)
y_pred_f = final_knn.predict(x_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred_f))
print("Best Parameters:", best_params)

"""Fine-tuning on transformed dataframe"""

param_grid = {
    'weights': ['uniform', 'distance'],  # weighting scheme for neighbors
    'p': [1, 2],  # power parameter for the Minkowski distance metric (1: Manhattan, 2: Euclidean)
}

grid_search = GridSearchCV(knn, param_grid)
grid_search.fit(x_train1, y_train1)
best_params = grid_search.best_params_

final_knn = KNeighborsClassifier(n_neighbors=5, **best_params)
final_knn.fit(x_train1, y_train1)
y_pred_f = final_knn.predict(x_test1)

print("Accuracy:",metrics.accuracy_score(y_test1, y_pred_f))
print("Best Parameters:", best_params)